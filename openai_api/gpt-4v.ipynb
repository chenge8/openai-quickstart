{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b6a552-b7f0-433d-9a70-61c4fcc52d5d",
   "metadata": {},
   "source": [
    "# 快速入门 GPT-4 Vison\n",
    "\n",
    "从历史上看，语言模型系统仅接受**文本**作为输入。但是单一的输入形式，限制了大模型的应用落地范围。\n",
    "\n",
    "随着技术发展，OpenAI 开发的 GPT-4 Turbo with Vision（简称 GPT-4V）允许模型接收**图像**作为输入，并回答关于它们的问题。\n",
    "\n",
    "📢注意，目前在 Assistants API 中使用 GPT-4 时还不支持图像输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a701c56-0a2a-4dea-b458-234150b84ff2",
   "metadata": {},
   "source": [
    "## 使用 GPT-4V 识别线上图像（URL）\n",
    "\n",
    "![image_sample](https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf8689b2-94f2-4a35-a332-9ffed0a56aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='这幅图展示了一条木板路穿越广阔、绿意盎然的草地，仿佛引导观者深入自然之中。图中的天空明朗，云朵稀疏，呈现出宁静愉悦的氛围。木板路两侧的草地郁郁葱葱，颜色鲜明，生机勃勃，与蓝天形成鲜明对比。这种景观常见于公园或自然保护区，旨在为访客提供探索自然之美的安全通道，同时保护地面植被。整体而言，这是一幅表现自然风光和人类与自然和谐共处的美丽图像。', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"介绍下这幅图?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bcc9026-7485-428f-8269-ea9ae41405cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这幅图展示了一条木板路穿越广阔、绿意盎然的草地，仿佛引导观者深入自然之中。图中的天空明朗，云朵稀疏，呈现出宁静愉悦的氛围。木板路两侧的草地郁郁葱葱，颜色鲜明，生机勃勃，与蓝天形成鲜明对比。这种景观常见于公园或自然保护区，旨在为访客提供探索自然之美的安全通道，同时保护地面植被。整体而言，这是一幅表现自然风光和人类与自然和谐共处的美丽图像。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb50a14-fa14-4c63-9f81-b98b0f65d9d9",
   "metadata": {},
   "source": [
    "### 封装成一个函数 query_image_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ca5428-c7e1-4d7e-91f1-d4a05e95ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_image_description(url, prompt=\"介绍下这幅图?\"):\n",
    "    client = OpenAI()  # 初始化 OpenAI 客户端\n",
    "    \n",
    "    # 发送请求给 OpenAI 的聊天模型\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",  # 指定使用的模型\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": url}},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "    )\n",
    "    \n",
    "    # 返回模型的响应\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d0aceb-7cc5-4da1-b6db-e47716ba145a",
   "metadata": {},
   "source": [
    "### 调用函数测试\n",
    "\n",
    "![meme_0](https://p6.itc.cn/q_70/images03/20200602/0c267a0d3d814c9783659eb956969ba1.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "454abb5c-49d3-42e6-867e-f44e25af5e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这幅图非常有趣，它展示了两种不同类型的化身，被调侃地形容为“16岁的我”与“工作后的我”。左边是一只肌肉发达的狗，形似一名健身运动员，上方标注为“16岁的我”，下面有标签说明它具有强壮的身体和力量，强调爱美丽与年轻的特点。右边是一只看起来有些憔悴和消瘦的狗，被标记为“工作后的我”，其相关标签则强调工作压力和生活的艰辛，展示了疲惫和困倦的状态。整体上，这幅图通过幽默和夸张来表达人在青少年时期与成年工作后可能出现的身心变化。这种插图通常用于社交媒体上以幽默方式表达生活感悟。\n"
     ]
    }
   ],
   "source": [
    "image_url = \"https://p6.itc.cn/q_70/images03/20200602/0c267a0d3d814c9783659eb956969ba1.jpeg\"\n",
    "content = query_image_description(image_url)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2471306a-84e2-4793-b065-0741fbe57262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79850f-83b5-49c4-a3f3-f2c01a28f458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63ae05bd-872c-4638-8259-df4f420aaa1d",
   "metadata": {},
   "source": [
    "### 使用 GPT-4V 识别本地图像文件（Base64编码）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e83da68-d387-46da-8236-78fc607d1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "\n",
    "client = OpenAI()  # 初始化 OpenAI 客户端\n",
    "\n",
    "def query_base64_image_description(image_path, prompt=\"解释下图里的内容？\", max_tokens=1000):\n",
    "\n",
    "    # 实现 Base64 编码\n",
    "    def encode_image(path):\n",
    "        with open(path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # 获取图像的 Base64 编码字符串\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    # 构造请求的 HTTP Header\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {client.api_key}\"\n",
    "    }\n",
    "\n",
    "    # 构造请求的负载\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "\n",
    "    # 发送 HTTP 请求\n",
    "    response = requests.post(\"https://api.xiaoai.plus/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    # 检查响应并提取所需的 content 字段\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        content = response_data['choices'][0]['message']['content']\n",
    "        return content\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd0f99-8086-473f-80a4-497e6dd07c17",
   "metadata": {},
   "source": [
    "#### 使用 Assistants API生成的 GDP 40年对比曲线图\n",
    "\n",
    "![gdp_data](./images/gdp_1980_2020.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0e9063-e8d9-4bc1-ae60-ad0aa5bee32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这幅图显示了1980年至2020年期间美国、中国、日本和德国的国内生产总值（GDP）的比较。从图中可以看出以下几点：\n",
      "\n",
      "1. **美国（蓝线）**：美国GDP持续增长，1980年约为2.5万亿美元，并在40年的时间里稳步上升至超过20万亿美元。\n",
      "\n",
      "2. **中国（红线）**：中国的GDP增长非常显著。从1980年的几乎接近于0万亿美元，到2020年增长至约14万亿美元。特别是从2000年开始，中国GDP的增长速度加快，显示出迅猛的经济发展。\n",
      "\n",
      "3. **日本（紫线）**：日本的GDP在1980年到1995年期间稳步增长，达到约5万亿美元的高峰。然而，自那时以后，日本的GDP增长放缓，并在5万亿到6万亿美元之间波动。\n",
      "\n",
      "4. **德国（绿线）**：德国的GDP增长较为平稳，从1980年的不到1万亿美元增长至约4万亿美元。\n",
      "\n",
      "整体来看，这幅图表反映了这四个国家在过去40年内的经济增长情况，显示美国和中国的GDP增长尤为显著，而日本和德国的增长则较为缓慢。\n"
     ]
    }
   ],
   "source": [
    "content = query_base64_image_description(\"./images/gdp_1980_2020.jpg\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18b227-32a6-4450-86bd-c99ad5c533b9",
   "metadata": {},
   "source": [
    "#### 使用 GPT-4V 识别手写体笔记\n",
    "\n",
    "![](./images/handwriting_0.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4193fa11-5edd-404c-9472-0cb8cc6799fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这张图片展示的是一本笔记本上关于机器学习模型微调技术的笔记，特别是关于变换器模型（如BERT或GPT等）的变体方法。文中讨论了几种不同的微调技术，包括：\n",
      "\n",
      "1. **Prompt Tuning**: This involves adjusting or optimizing a prompt to steer the outputs of a pre-trained model for specific tasks without altering the model parameters substantially. Often used with smaller models.\n",
      "\n",
      "2. **Prefix Tuning**: In this method, a sequence of continuous vectors (prefixes) is prepended to the input, and these vectors are optimized during training while keeping the underlying model's weights frozen.\n",
      "\n",
      "3. **LoRA (Low-Rank Adaptation)**: LoRA modifies the attention mechanism of transformer models by adding low-rank matrices to the weights. This means changes to the model are restricted to a lower-dimensional subspace, which reduces the amount of parameters that need updating.\n",
      "\n",
      "笔记中详细记录了这些技术的数学表述和一些实现细节。例如，LoRA技术中的公式 \\( Y = (W + \\Delta W) X \\)，其中 \\( \\Delta W = AB \\)，说明了是如何通过低秩矩阵 \\( AB \\) 来近似权重的变化。还提到了一些具体的数据存储需求，例如 QLoRA 模型需要 78GB存储空间，而 LLaMA模型使用的QLoRA只需 48GB。\n"
     ]
    }
   ],
   "source": [
    "content = query_base64_image_description(\"./images/handwriting_0.jpg\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca046601-018c-455c-ace2-41392cbda456",
   "metadata": {},
   "source": [
    "#### 在 Jupyter 标准输出中渲染 Markdown 格式内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516ee35b-1337-4b22-aea2-ee0adb706098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "这张图片展示的是一本笔记本上关于机器学习模型微调技术的笔记，特别是关于变换器模型（如BERT或GPT等）的变体方法。文中讨论了几种不同的微调技术，包括：\n",
       "\n",
       "1. **Prompt Tuning**: This involves adjusting or optimizing a prompt to steer the outputs of a pre-trained model for specific tasks without altering the model parameters substantially. Often used with smaller models.\n",
       "\n",
       "2. **Prefix Tuning**: In this method, a sequence of continuous vectors (prefixes) is prepended to the input, and these vectors are optimized during training while keeping the underlying model's weights frozen.\n",
       "\n",
       "3. **LoRA (Low-Rank Adaptation)**: LoRA modifies the attention mechanism of transformer models by adding low-rank matrices to the weights. This means changes to the model are restricted to a lower-dimensional subspace, which reduces the amount of parameters that need updating.\n",
       "\n",
       "笔记中详细记录了这些技术的数学表述和一些实现细节。例如，LoRA技术中的公式 \\( Y = (W + \\Delta W) X \\)，其中 \\( \\Delta W = AB \\)，说明了是如何通过低秩矩阵 \\( AB \\) 来近似权重的变化。还提到了一些具体的数据存储需求，例如 QLoRA 模型需要 78GB存储空间，而 LLaMA模型使用的QLoRA只需 48GB。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# 使用 display 和 Markdown 函数显示 Markdown 内容\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72ebbe3-87cc-4867-9cf0-62e5ed684482",
   "metadata": {},
   "source": [
    "![](./images/handwriting_1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c046958-aa7a-4066-88fa-4134869d9226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "这张图片显示的是一本笔记本的两页，里面记录了有关自然语言处理（NLP）和大型语言模型（LLMs）的一些高级主题和研究方法。内容涵盖了多种不同的调整和优化语言模型的技术：\n",
       "\n",
       "1. 左侧页面：\n",
       "   - 开头提到了`一阶Transformers技术`和`技术`下有`Benchmark`进行性能评估。\n",
       "   - 下方列举了不同的模型调优方法，如`PEFT`、`SOTA`（State Of The Art，技术前沿）和`PBFT Methods`。\n",
       "   - 进行了`Prompt Tuning`的特别说明，涉及不同年份和组织，例如Google和Stanford。\n",
       "   - 底部提到了高级语言模型，如`GPT、XLMH、ChatGLM、BLOOM`和`Alpaca`等。\n",
       "\n",
       "2. 右侧页面：\n",
       "   - 右边页起始处提到了`multi-modality`和`Instruction Fine-Tuning`（指令微调），给出了具体的例子比如`LLaMA(33B)`。\n",
       "   - 提到了新的模型`LaRa`和`PETC`，及其相关技术。\n",
       "   - 研究了`Prefix-tuning`和`Adaptors`的技术性区分，并讨论了在大型语言模型中的Refine技巧。\n",
       "   - 还有对`MAM Adaptors`的讨论，包括架构设计和效果提升的描述。\n",
       "\n",
       "这些笔记显示，作者正在研究或学习关于如何通过各种方法优化或调整语言模型的技术细节。这可能是在计算机科学、特别是自然语言处理领域的高级学习或研究的一部分。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "content = query_base64_image_description(\"./images/handwriting_1.jpg\")\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd772f-9492-4f6c-b05a-666b772ca3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afdeacb-aac1-4692-be2b-fb7957ba5e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79a8d459-d98e-4215-9fbf-38ad37080475",
   "metadata": {},
   "source": [
    "## Homework: \n",
    "\n",
    "\n",
    "### #1\n",
    "\n",
    "使用 GPT-4V 识别带有手写体文字的本地图像文件，分享结果。\n",
    "\n",
    "### #2\n",
    "\n",
    "整合 `query_base64_image_description` 函数和 Markdown 格式渲染方法，使得输出结果更易阅读。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b10a00",
   "metadata": {},
   "source": [
    "![](./images/vita-drink.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63a52b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "\n",
    "client = OpenAI()  # 初始化 OpenAI 客户端\n",
    "\n",
    "def query_base64_image_description2(image_path, prompt, max_tokens=1000):\n",
    "\n",
    "    # 实现 Base64 编码\n",
    "    def encode_image(path):\n",
    "        with open(path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # 获取图像的 Base64 编码字符串\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    # 构造请求的 HTTP Header\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {client.api_key}\"\n",
    "    }\n",
    "\n",
    "    # 构造请求的负载\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "\n",
    "    # 发送 HTTP 请求\n",
    "    response = requests.post(\"https://api.xiaoai.plus/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    # 检查响应并提取所需的 content 字段\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        content = response_data['choices'][0]['message']['content']\n",
    "        return content\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0909bf27-9c4a-498c-9fae-0f442062b9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "这张图片显示的产品是豆奶粉。我们可以通过包装上的文字了解到，这是植物蛋白饮品，由大豆蛋白分离物等成分制成。此外，包装上还列出了营养成分表，包括蛋白质、碳水化合物、钠等成分的含量。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "content = query_base64_image_description2(\"./images/vita-drink.jpg\",\"此产品的类型是什么？\")\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28e29d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('langchain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f6010711af08dd8d8b51f030b166c3d42d23b75e610d39e3e943e5486ce548d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
